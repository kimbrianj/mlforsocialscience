<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />



<meta name="progressive" content="true" />
<meta name="allow-skip" content="false" />

<title>ML Toolbox</title>


<!-- highlightjs -->
<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>

<!-- taken from https://github.com/rstudio/rmarkdown/blob/67b7f5fc779e4cfdfd0f021d3d7745b6b6e17149/inst/rmd/h/default.html#L296-L362 -->
<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("section-TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>
<!-- end tabsets -->



</head>

<body>



<div class="pageContent band">
<div class="bandContent page">

<div class="topics">

<div id="section-setup" class="section level2">
<h2>Setup</h2>
<pre class="r"><code>library(tidyverse)
library(magrittr)
library(titanic)
library(caret)
library(DMwR)
library(ranger)
library(party)
library(caretEnsemble)
library(SuperLearner)
library(pROC)</code></pre>
<div id="section-data" class="section level3">
<h3>Data</h3>
<p>In this notebook we use the Titanic data. It includes information on a set of Titanic passengers, such as age, sex, ticket class and whether he or she survived the Titanic tragedy (Note that the <code>titanic</code> package also provides a separate test set that precludes the survival variable).</p>
<p>Source: <a href="https://www.kaggle.com/c/titanic/data" class="uri">https://www.kaggle.com/c/titanic/data</a></p>
<pre class="r"><code>titanic &lt;- titanic_train
str(titanic)</code></pre>
<pre><code>## &#39;data.frame&#39;:    891 obs. of  12 variables:
##  $ PassengerId: int  1 2 3 4 5 6 7 8 9 10 ...
##  $ Survived   : int  0 1 1 1 0 0 0 0 1 1 ...
##  $ Pclass     : int  3 1 3 1 3 3 1 3 3 2 ...
##  $ Name       : chr  &quot;Braund, Mr. Owen Harris&quot; &quot;Cumings, Mrs. John Bradley (Florence Briggs Thayer)&quot; &quot;Heikkinen, Miss. Laina&quot; &quot;Futrelle, Mrs. Jacques Heath (Lily May Peel)&quot; ...
##  $ Sex        : chr  &quot;male&quot; &quot;female&quot; &quot;female&quot; &quot;female&quot; ...
##  $ Age        : num  22 38 26 35 35 NA 54 2 27 14 ...
##  $ SibSp      : int  1 1 0 1 0 0 0 3 0 1 ...
##  $ Parch      : int  0 0 0 0 0 0 0 1 2 0 ...
##  $ Ticket     : chr  &quot;A/5 21171&quot; &quot;PC 17599&quot; &quot;STON/O2. 3101282&quot; &quot;113803&quot; ...
##  $ Fare       : num  7.25 71.28 7.92 53.1 8.05 ...
##  $ Cabin      : chr  &quot;&quot; &quot;C85&quot; &quot;&quot; &quot;C123&quot; ...
##  $ Embarked   : chr  &quot;S&quot; &quot;C&quot; &quot;S&quot; &quot;S&quot; ...</code></pre>
<p>We begin with some minor data preparations.</p>
<pre class="r"><code>titanic$Survived &lt;- as.factor(titanic$Survived)
levels(titanic$Survived) &lt;- make.names(levels(factor(titanic$Survived)))
titanic %&lt;&gt;%
  select(Survived, Pclass, Sex, Age, Fare) %&gt;%
  na.omit(.)</code></pre>
<p>Next we split the data into a training and a test part. This can be done by stratified random sampling with <code>createDataPartition()</code>.</p>
<pre class="r"><code>set.seed(3225)
inTrain &lt;- createDataPartition(titanic$Survived, 
                               p = .8, 
                               list = FALSE, 
                               times = 1)
titanic_train &lt;- titanic[inTrain,]
titanic_test &lt;- titanic[-inTrain,]</code></pre>
</div>
<div id="section-tuning-setup" class="section level3">
<h3>Tuning Setup</h3>
<p>In this notebook, we will consider another add-on in the tuning process. We use stratified cross-validation since we have imbalanced classes in our outcome. We therefore set up a cv-index using <code>createFolds()</code>.</p>
<pre class="r"><code>cvIndex &lt;- createFolds(titanic_train$Survived, 5, returnTrain = T)</code></pre>
<p>The cvIndex object can now be passed on to <code>trainControl()</code> to guide the tuning process in the next sections.</p>
<pre class="r"><code>ctrl &lt;- trainControl(method = &quot;cv&quot;,
                     number = 5,
                     index = cvIndex,
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE,
                     verboseIter = TRUE,
                     savePredictions = &quot;final&quot;)</code></pre>
</div>
</div>
<div id="section-random-forest-extra-trees" class="section level2">
<h2>Random Forest &amp; Extra Trees</h2>
<p>We start with random forests and extremely randomized trees. In order to specify reasonable values for <code>mtry</code>, <code>model.matrix()</code> is a handy function as it creates dummy variables for all factors of a specified model.</p>
<pre class="r"><code>cols &lt;- ncol(model.matrix(Survived ~ ., data = titanic_train))</code></pre>
<p>Here we only consider two try-out values to limit the time needed for model tuning. We specify the tree building methods via <code>splitrule</code>.</p>
<pre class="r"><code>grid &lt;- expand.grid(mtry = c(sqrt(cols), log(cols)),
                    splitrule = c(&quot;gini&quot;, &quot;extratrees&quot;),
                    min.node.size = 10)
grid</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["mtry"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["splitrule"],"name":[2],"type":["fct"],"align":["left"]},{"label":["min.node.size"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"2.236068","2":"gini","3":"10"},{"1":"1.609438","2":"gini","3":"10"},{"1":"2.236068","2":"extratrees","3":"10"},{"1":"1.609438","2":"extratrees","3":"10"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Start the tuning process. We are looking for the model with the maximum ROC-AUC.</p>
<pre class="r"><code>rf &lt;- train(Survived ~ .,
            data = titanic_train,
            method = &quot;ranger&quot;,
            trControl = ctrl,
            tuneGrid = grid,
            metric = &quot;ROC&quot;)</code></pre>
<pre><code>## + Fold1: mtry=2.236, splitrule=gini, min.node.size=10 
## - Fold1: mtry=2.236, splitrule=gini, min.node.size=10 
## + Fold1: mtry=1.609, splitrule=gini, min.node.size=10 
## - Fold1: mtry=1.609, splitrule=gini, min.node.size=10 
## + Fold1: mtry=2.236, splitrule=extratrees, min.node.size=10 
## - Fold1: mtry=2.236, splitrule=extratrees, min.node.size=10 
## + Fold1: mtry=1.609, splitrule=extratrees, min.node.size=10 
## - Fold1: mtry=1.609, splitrule=extratrees, min.node.size=10 
## + Fold2: mtry=2.236, splitrule=gini, min.node.size=10 
## - Fold2: mtry=2.236, splitrule=gini, min.node.size=10 
## + Fold2: mtry=1.609, splitrule=gini, min.node.size=10 
## - Fold2: mtry=1.609, splitrule=gini, min.node.size=10 
## + Fold2: mtry=2.236, splitrule=extratrees, min.node.size=10 
## - Fold2: mtry=2.236, splitrule=extratrees, min.node.size=10 
## + Fold2: mtry=1.609, splitrule=extratrees, min.node.size=10 
## - Fold2: mtry=1.609, splitrule=extratrees, min.node.size=10 
## + Fold3: mtry=2.236, splitrule=gini, min.node.size=10 
## - Fold3: mtry=2.236, splitrule=gini, min.node.size=10 
## + Fold3: mtry=1.609, splitrule=gini, min.node.size=10 
## - Fold3: mtry=1.609, splitrule=gini, min.node.size=10 
## + Fold3: mtry=2.236, splitrule=extratrees, min.node.size=10 
## - Fold3: mtry=2.236, splitrule=extratrees, min.node.size=10 
## + Fold3: mtry=1.609, splitrule=extratrees, min.node.size=10 
## - Fold3: mtry=1.609, splitrule=extratrees, min.node.size=10 
## + Fold4: mtry=2.236, splitrule=gini, min.node.size=10 
## - Fold4: mtry=2.236, splitrule=gini, min.node.size=10 
## + Fold4: mtry=1.609, splitrule=gini, min.node.size=10 
## - Fold4: mtry=1.609, splitrule=gini, min.node.size=10 
## + Fold4: mtry=2.236, splitrule=extratrees, min.node.size=10 
## - Fold4: mtry=2.236, splitrule=extratrees, min.node.size=10 
## + Fold4: mtry=1.609, splitrule=extratrees, min.node.size=10 
## - Fold4: mtry=1.609, splitrule=extratrees, min.node.size=10 
## + Fold5: mtry=2.236, splitrule=gini, min.node.size=10 
## - Fold5: mtry=2.236, splitrule=gini, min.node.size=10 
## + Fold5: mtry=1.609, splitrule=gini, min.node.size=10 
## - Fold5: mtry=1.609, splitrule=gini, min.node.size=10 
## + Fold5: mtry=2.236, splitrule=extratrees, min.node.size=10 
## - Fold5: mtry=2.236, splitrule=extratrees, min.node.size=10 
## + Fold5: mtry=1.609, splitrule=extratrees, min.node.size=10 
## - Fold5: mtry=1.609, splitrule=extratrees, min.node.size=10 
## Aggregating results
## Selecting tuning parameters
## Fitting mtry = 2.24, splitrule = extratrees, min.node.size = 10 on full training set</code></pre>
<p>List the tuning results.</p>
<pre class="r"><code>rf</code></pre>
<pre><code>## Random Forest 
## 
## 572 samples
##   4 predictor
##   2 classes: &#39;X0&#39;, &#39;X1&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 457, 458, 458, 458, 457 
## Resampling results across tuning parameters:
## 
##   mtry      splitrule   ROC        Sens       Spec     
##   1.609438  gini        0.8645549  0.8941176  0.6504163
##   1.609438  extratrees  0.8659085  0.8911765  0.6850139
##   2.236068  gini        0.8708222  0.8911765  0.7065680
##   2.236068  extratrees  0.8713575  0.8970588  0.6978723
## 
## Tuning parameter &#39;min.node.size&#39; was held constant at a value of 10
## ROC was used to select the optimal model using the largest value.
## The final values used for the model were mtry = 2.236068, splitrule
##  = extratrees and min.node.size = 10.</code></pre>
</div>
<div id="section-smote" class="section level2">
<h2>SMOTE</h2>
<p>In this section we investigate whether up-sampling the minority class helps to train better prediction models. One option is using <code>SMOTE()</code> from the <code>DMwR</code> package.</p>
<pre class="r"><code>?SMOTE</code></pre>
<p>However, here we use caret as a wrapper for this function and directly specify SMOTE in the <code>sampling</code> argument of <code>trainControl()</code>.</p>
<pre class="r"><code>ctrl2 &lt;- trainControl(method = &quot;cv&quot;,
                      number = 5,
                      summaryFunction = twoClassSummary,
                      classProbs = TRUE,
                      verboseIter = TRUE,
                      sampling = &quot;smote&quot;)</code></pre>
<p>Lets again train and tune random forests and extremely randomized trees, this time with modified training data.</p>
<pre class="r"><code>rf_s &lt;- train(Survived ~ .,
              data = titanic_train,
              method = &quot;ranger&quot;,
              trControl = ctrl2,
              tuneGrid = grid,
              metric = &quot;ROC&quot;)</code></pre>
<pre><code>## + Fold1: mtry=2.236, splitrule=gini, min.node.size=10 
## - Fold1: mtry=2.236, splitrule=gini, min.node.size=10 
## + Fold1: mtry=1.609, splitrule=gini, min.node.size=10 
## - Fold1: mtry=1.609, splitrule=gini, min.node.size=10 
## + Fold1: mtry=2.236, splitrule=extratrees, min.node.size=10 
## - Fold1: mtry=2.236, splitrule=extratrees, min.node.size=10 
## + Fold1: mtry=1.609, splitrule=extratrees, min.node.size=10 
## - Fold1: mtry=1.609, splitrule=extratrees, min.node.size=10 
## + Fold2: mtry=2.236, splitrule=gini, min.node.size=10 
## - Fold2: mtry=2.236, splitrule=gini, min.node.size=10 
## + Fold2: mtry=1.609, splitrule=gini, min.node.size=10 
## - Fold2: mtry=1.609, splitrule=gini, min.node.size=10 
## + Fold2: mtry=2.236, splitrule=extratrees, min.node.size=10 
## - Fold2: mtry=2.236, splitrule=extratrees, min.node.size=10 
## + Fold2: mtry=1.609, splitrule=extratrees, min.node.size=10 
## - Fold2: mtry=1.609, splitrule=extratrees, min.node.size=10 
## + Fold3: mtry=2.236, splitrule=gini, min.node.size=10 
## - Fold3: mtry=2.236, splitrule=gini, min.node.size=10 
## + Fold3: mtry=1.609, splitrule=gini, min.node.size=10 
## - Fold3: mtry=1.609, splitrule=gini, min.node.size=10 
## + Fold3: mtry=2.236, splitrule=extratrees, min.node.size=10 
## - Fold3: mtry=2.236, splitrule=extratrees, min.node.size=10 
## + Fold3: mtry=1.609, splitrule=extratrees, min.node.size=10 
## - Fold3: mtry=1.609, splitrule=extratrees, min.node.size=10 
## + Fold4: mtry=2.236, splitrule=gini, min.node.size=10 
## - Fold4: mtry=2.236, splitrule=gini, min.node.size=10 
## + Fold4: mtry=1.609, splitrule=gini, min.node.size=10 
## - Fold4: mtry=1.609, splitrule=gini, min.node.size=10 
## + Fold4: mtry=2.236, splitrule=extratrees, min.node.size=10 
## - Fold4: mtry=2.236, splitrule=extratrees, min.node.size=10 
## + Fold4: mtry=1.609, splitrule=extratrees, min.node.size=10 
## - Fold4: mtry=1.609, splitrule=extratrees, min.node.size=10 
## + Fold5: mtry=2.236, splitrule=gini, min.node.size=10 
## - Fold5: mtry=2.236, splitrule=gini, min.node.size=10 
## + Fold5: mtry=1.609, splitrule=gini, min.node.size=10 
## - Fold5: mtry=1.609, splitrule=gini, min.node.size=10 
## + Fold5: mtry=2.236, splitrule=extratrees, min.node.size=10 
## - Fold5: mtry=2.236, splitrule=extratrees, min.node.size=10 
## + Fold5: mtry=1.609, splitrule=extratrees, min.node.size=10 
## - Fold5: mtry=1.609, splitrule=extratrees, min.node.size=10 
## Aggregating results
## Selecting tuning parameters
## Fitting mtry = 2.24, splitrule = extratrees, min.node.size = 10 on full training set</code></pre>
<p>Print the tuning results.</p>
<pre class="r"><code>rf_s</code></pre>
<pre><code>## Random Forest 
## 
## 572 samples
##   4 predictor
##   2 classes: &#39;X0&#39;, &#39;X1&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 458, 457, 458, 458, 457 
## Addtional sampling using SMOTE
## 
## Resampling results across tuning parameters:
## 
##   mtry      splitrule   ROC        Sens       Spec     
##   1.609438  gini        0.8594146  0.8617647  0.7417206
##   1.609438  extratrees  0.8540275  0.8823529  0.7069380
##   2.236068  gini        0.8596704  0.8617647  0.7328400
##   2.236068  extratrees  0.8662384  0.8705882  0.7284921
## 
## Tuning parameter &#39;min.node.size&#39; was held constant at a value of 10
## ROC was used to select the optimal model using the largest value.
## The final values used for the model were mtry = 2.236068, splitrule
##  = extratrees and min.node.size = 10.</code></pre>
</div>
<div id="section-stacking" class="section level2">
<h2>Stacking</h2>
<p>We may also want to consider a meta-model that is built on top of the predictions of lower level models. Here we consider the <code>caretEnsemble</code> package. For simplicity, we only use CTREE and a logistic regression as base methods. As a first step, the lower level models have to be build.</p>
<pre class="r"><code>model_list &lt;- caretList(Survived ~ .,
                        data = titanic_train,
                        trControl = ctrl,
                        metric = &quot;ROC&quot;,
                        methodList = c(&quot;ctree&quot;, &quot;glm&quot;))</code></pre>
<pre><code>## + Fold1: mincriterion=0.99 
## - Fold1: mincriterion=0.99 
## + Fold1: mincriterion=0.50 
## - Fold1: mincriterion=0.50 
## + Fold1: mincriterion=0.01 
## - Fold1: mincriterion=0.01 
## + Fold2: mincriterion=0.99 
## - Fold2: mincriterion=0.99 
## + Fold2: mincriterion=0.50 
## - Fold2: mincriterion=0.50 
## + Fold2: mincriterion=0.01 
## - Fold2: mincriterion=0.01 
## + Fold3: mincriterion=0.99 
## - Fold3: mincriterion=0.99 
## + Fold3: mincriterion=0.50 
## - Fold3: mincriterion=0.50 
## + Fold3: mincriterion=0.01 
## - Fold3: mincriterion=0.01 
## + Fold4: mincriterion=0.99 
## - Fold4: mincriterion=0.99 
## + Fold4: mincriterion=0.50 
## - Fold4: mincriterion=0.50 
## + Fold4: mincriterion=0.01 
## - Fold4: mincriterion=0.01 
## + Fold5: mincriterion=0.99 
## - Fold5: mincriterion=0.99 
## + Fold5: mincriterion=0.50 
## - Fold5: mincriterion=0.50 
## + Fold5: mincriterion=0.01 
## - Fold5: mincriterion=0.01 
## Aggregating results
## Selecting tuning parameters
## Fitting mincriterion = 0.5 on full training set
## + Fold1: parameter=none 
## - Fold1: parameter=none 
## + Fold2: parameter=none 
## - Fold2: parameter=none 
## + Fold3: parameter=none 
## - Fold3: parameter=none 
## + Fold4: parameter=none 
## - Fold4: parameter=none 
## + Fold5: parameter=none 
## - Fold5: parameter=none 
## Aggregating results
## Fitting final model on full training set</code></pre>
<p>The resulting object includes the training and tuning results for both methods.</p>
<pre class="r"><code>model_list</code></pre>
<pre><code>## $ctree
## Conditional Inference Tree 
## 
## 572 samples
##   4 predictor
##   2 classes: &#39;X0&#39;, &#39;X1&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 457, 458, 458, 458, 457 
## Resampling results across tuning parameters:
## 
##   mincriterion  ROC        Sens       Spec     
##   0.01          0.8394889  0.8911765  0.6632747
##   0.50          0.8439544  0.8970588  0.6545791
##   0.99          0.8360852  0.9352941  0.5727105
## 
## ROC was used to select the optimal model using the largest value.
## The final value used for the model was mincriterion = 0.5.
## 
## $glm
## Generalized Linear Model 
## 
## 572 samples
##   4 predictor
##   2 classes: &#39;X0&#39;, &#39;X1&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 457, 458, 458, 458, 457 
## Resampling results:
## 
##   ROC       Sens       Spec     
##   0.854139  0.8529412  0.7236818
## 
## 
## attr(,&quot;class&quot;)
## [1] &quot;caretList&quot;</code></pre>
<p>We can briefly check the similarity of the predictions across models.</p>
<pre class="r"><code>as.data.frame(predict(model_list, newdata = head(titanic_train)))</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["ctree"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["glm"],"name":[2],"type":["dbl"],"align":["right"]}],"data":[{"1":"0.88278388","2":"0.89420314"},{"1":"0.04878049","2":"0.07537983"},{"1":"0.88278388","2":"0.93309772"},{"1":"0.85000000","2":"0.66293907"},{"1":"0.33333333","2":"0.79508021"},{"1":"0.26190476","2":"0.44255755"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>modelCor(resamples(model_list))</code></pre>
<pre><code>##         ctree     glm
## ctree 1.00000 0.96793
## glm   0.96793 1.00000</code></pre>
<p>Now we build a higher level model by using the predictions of the previous models as inputs in a logistic regression. This can be implemented with <code>caretStack()</code>.</p>
<pre class="r"><code>glm_ensemble &lt;- caretStack(model_list,
                           method = &quot;glm&quot;,
                           trControl = trainControl(
                             method = &quot;cv&quot;,
                             number = 5,
                             savePredictions = &quot;final&quot;,
                             classProbs = TRUE,
                             summaryFunction = twoClassSummary))</code></pre>
<pre><code>## Warning in train.default(predobs$preds, predobs$obs, ...): The metric &quot;Accuracy&quot;
## was not in the result set. ROC will be used instead.</code></pre>
<p>List the cross-validation results of the stacking ensemble.</p>
<pre class="r"><code>glm_ensemble</code></pre>
<pre><code>## A glm ensemble of 2 base models: ctree, glm
## 
## Ensemble results:
## Generalized Linear Model 
## 
## 572 samples
##   2 predictor
##   2 classes: &#39;X0&#39;, &#39;X1&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 458, 458, 458, 457, 457 
## Resampling results:
## 
##   ROC        Sens       Spec    
##   0.8525507  0.8764706  0.706568</code></pre>
<p>We can also access the coefficients of the meta logit model via <code>coef</code>.</p>
<pre class="r"><code>coef(glm_ensemble$ens_model$finalModel)</code></pre>
<pre><code>## (Intercept)       ctree         glm 
##    2.653925   -2.269761   -2.988444</code></pre>
</div>
<div id="section-super-learner" class="section level2">
<h2>Super Learner</h2>
<p>As an alternative to <code>caretEnsemble</code>, the <code>SuperLearner</code> package can be used for building a meta-ensemble model. This package needs a slightly different data setup, i.e. X and y objects for the train and test data.</p>
<pre class="r"><code>X_train &lt;- titanic_train[which(names(titanic_train) != &quot;Survived&quot;)]
y_train &lt;- ifelse(titanic_train$Survived == &quot;X1&quot;, 1, 0)
X_test &lt;- titanic_test[which(names(titanic_test) != &quot;Survived&quot;)]</code></pre>
<p>The function <code>listWrappers()</code> lists the model types that we can use as individual learners.</p>
<pre class="r"><code>listWrappers()</code></pre>
<pre><code>## All prediction algorithm wrappers in SuperLearner:</code></pre>
<pre><code>##  [1] &quot;SL.bartMachine&quot;      &quot;SL.bayesglm&quot;         &quot;SL.biglasso&quot;        
##  [4] &quot;SL.caret&quot;            &quot;SL.caret.rpart&quot;      &quot;SL.cforest&quot;         
##  [7] &quot;SL.earth&quot;            &quot;SL.extraTrees&quot;       &quot;SL.gam&quot;             
## [10] &quot;SL.gbm&quot;              &quot;SL.glm&quot;              &quot;SL.glm.interaction&quot; 
## [13] &quot;SL.glmnet&quot;           &quot;SL.ipredbagg&quot;        &quot;SL.kernelKnn&quot;       
## [16] &quot;SL.knn&quot;              &quot;SL.ksvm&quot;             &quot;SL.lda&quot;             
## [19] &quot;SL.leekasso&quot;         &quot;SL.lm&quot;               &quot;SL.loess&quot;           
## [22] &quot;SL.logreg&quot;           &quot;SL.mean&quot;             &quot;SL.nnet&quot;            
## [25] &quot;SL.nnls&quot;             &quot;SL.polymars&quot;         &quot;SL.qda&quot;             
## [28] &quot;SL.randomForest&quot;     &quot;SL.ranger&quot;           &quot;SL.ridge&quot;           
## [31] &quot;SL.rpart&quot;            &quot;SL.rpartPrune&quot;       &quot;SL.speedglm&quot;        
## [34] &quot;SL.speedlm&quot;          &quot;SL.step&quot;             &quot;SL.step.forward&quot;    
## [37] &quot;SL.step.interaction&quot; &quot;SL.stepAIC&quot;          &quot;SL.svm&quot;             
## [40] &quot;SL.template&quot;         &quot;SL.xgboost&quot;</code></pre>
<pre><code>## 
## All screening algorithm wrappers in SuperLearner:</code></pre>
<pre><code>## [1] &quot;All&quot;
## [1] &quot;screen.corP&quot;           &quot;screen.corRank&quot;        &quot;screen.glmnet&quot;        
## [4] &quot;screen.randomForest&quot;   &quot;screen.SIS&quot;            &quot;screen.template&quot;      
## [7] &quot;screen.ttest&quot;          &quot;write.screen.template&quot;</code></pre>
<p>Here we choose a null model (<code>SL.mean</code>), elastic net (<code>SL.glmnet</code>) and random forests grown by ranger (<code>SL.ranger</code>) for building our Super Learner. Details on the construction of the higher level model can be found by calling <code>?method.template</code>.</p>
<pre class="r"><code>sl &lt;- SuperLearner(Y = y_train, X = X_train, family = binomial(),
                   SL.library = c(&quot;SL.mean&quot;, &quot;SL.glmnet&quot;, &quot;SL.ranger&quot;))</code></pre>
<pre><code>## Loading required namespace: glmnet</code></pre>
<pre class="r"><code>sl</code></pre>
<pre><code>## 
## Call:  
## SuperLearner(Y = y_train, X = X_train, family = binomial(), SL.library = c(&quot;SL.mean&quot;,  
##     &quot;SL.glmnet&quot;, &quot;SL.ranger&quot;)) 
## 
## 
##                    Risk      Coef
## SL.mean_All   0.2420988 0.0000000
## SL.glmnet_All 0.1434415 0.2010132
## SL.ranger_All 0.1303666 0.7989868</code></pre>
<p>We can also run nested Cross-Validation to get CV estimates for the performance of the individual models and the Super Learner.</p>
<pre class="r"><code>cv_sl &lt;- CV.SuperLearner(Y = y_train, X = X_train, family = binomial(), V = 5,
                        SL.library = c(&quot;SL.mean&quot;, &quot;SL.glmnet&quot;, &quot;SL.ranger&quot;))
cv_sl</code></pre>
<pre><code>## 
## Call:  
## CV.SuperLearner(Y = y_train, X = X_train, V = 5, family = binomial(), SL.library = c(&quot;SL.mean&quot;,  
##     &quot;SL.glmnet&quot;, &quot;SL.ranger&quot;)) 
## 
## 
## Cross-validated predictions from the SuperLearner:  SL.predict 
## 
## Cross-validated predictions from the discrete super learner (cross-validation selector):  discreteSL.predict 
## 
## Which library algorithm was the discrete super learner:  whichDiscreteSL 
## 
## Cross-validated prediction for all algorithms in the library:  library.predict</code></pre>
<pre class="r"><code>summary(cv_sl)</code></pre>
<pre><code>## 
## Call:  
## CV.SuperLearner(Y = y_train, X = X_train, V = 5, family = binomial(), SL.library = c(&quot;SL.mean&quot;,  
##     &quot;SL.glmnet&quot;, &quot;SL.ranger&quot;)) 
## 
## Risk is based on: Mean Squared Error
## 
## All risk estimates are based on V =  5 
## 
##      Algorithm     Ave        se     Min     Max
##  Super Learner 0.13268 0.0091214 0.11896 0.15390
##    Discrete SL 0.13754 0.0095505 0.11883 0.15364
##    SL.mean_All 0.24222 0.0039240 0.22946 0.24905
##  SL.glmnet_All 0.14318 0.0089212 0.13124 0.16968
##  SL.ranger_All 0.13207 0.0095405 0.11028 0.15364</code></pre>
<p>Plot the nested CV results.</p>
<pre class="r"><code>plot(cv_sl)</code></pre>
<p><img src="ml-toolbox_files/figure-html/unnamed-chunk-25-1.png" width="624" /></p>
</div>
<div id="section-prediction" class="section level2">
<h2>Prediction</h2>
<p>Finally, we create predicted risk scores for our outcome in the test set.</p>
<pre class="r"><code>p_rf &lt;- predict(rf, newdata = titanic_test, type = &quot;prob&quot;)
p_rf_s &lt;- predict(rf_s, newdata = titanic_test, type = &quot;prob&quot;)
p_ens &lt;- predict(glm_ensemble, newdata = titanic_test, type = &quot;prob&quot;)
p_sl &lt;- predict(sl, X_test, onlySL = TRUE)</code></pre>
<p>Creating ROC objects based on predicted probabilities…</p>
<pre class="r"><code>rf_roc &lt;- roc(titanic_test$Survived, p_rf$X1)</code></pre>
<pre><code>## Setting levels: control = X0, case = X1</code></pre>
<pre><code>## Setting direction: controls &lt; cases</code></pre>
<pre class="r"><code>rf_s_roc &lt;- roc(titanic_test$Survived, p_rf_s$X1)</code></pre>
<pre><code>## Setting levels: control = X0, case = X1
## Setting direction: controls &lt; cases</code></pre>
<pre class="r"><code>ens_roc &lt;- roc(titanic_test$Survived, p_ens)</code></pre>
<pre><code>## Setting levels: control = X0, case = X1</code></pre>
<pre><code>## Setting direction: controls &gt; cases</code></pre>
<pre class="r"><code>sl_roc &lt;- roc(titanic_test$Survived, p_sl$pred[, 1])</code></pre>
<pre><code>## Setting levels: control = X0, case = X1</code></pre>
<pre><code>## Setting direction: controls &lt; cases</code></pre>
<p>…and plotting the ROC curves.</p>
<pre class="r"><code>ggroc(list(RF = rf_roc, 
           RF_SMOTE = rf_s_roc, 
           Caret_Stack = ens_roc,
           SuperLearner = sl_roc)) +
  geom_segment(aes(x = 1, xend = 0, y = 0, yend = 1), 
               color=&quot;darkgrey&quot;, linetype=&quot;dashed&quot;)</code></pre>
<p><img src="ml-toolbox_files/figure-html/unnamed-chunk-28-1.png" width="624" /></p>
</div>
<div id="section-references" class="section level2">
<h2>References</h2>
<ul>
<li><a href="https://cran.r-project.org/web/packages/caretEnsemble/vignettes/caretEnsemble-intro.html" class="uri">https://cran.r-project.org/web/packages/caretEnsemble/vignettes/caretEnsemble-intro.html</a></li>
<li><a href="https://cran.r-project.org/web/packages/SuperLearner/vignettes/Guide-to-SuperLearner.html" class="uri">https://cran.r-project.org/web/packages/SuperLearner/vignettes/Guide-to-SuperLearner.html</a> <!--html_preserve-->
<script type="application/shiny-prerendered" data-context="dependencies">
{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootstrap"]},{"type":"character","attributes":{},"value":["3.3.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/bootstrap"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["viewport"]}},"value":[{"type":"character","attributes":{},"value":["width=device-width, initial-scale=1"]}]},{"type":"character","attributes":{},"value":["js/bootstrap.min.js","shim/html5shiv.min.js","shim/respond.min.js"]},{"type":"character","attributes":{},"value":["css/cerulean.min.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["pagedtable"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pagedtable-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["js/pagedtable.js"]},{"type":"character","attributes":{},"value":["css/pagedtable.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["textmate.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.10.1.9006"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9006"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-autocompletion"]},{"type":"character","attributes":{},"value":["0.10.1.9006"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-autocompletion.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9006"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-diagnostics"]},{"type":"character","attributes":{},"value":["0.10.1.9006"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-diagnostics.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9006"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-format"]},{"type":"character","attributes":{},"value":["0.10.1.9006"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmarkdown/templates/tutorial/resources"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-format.js"]},{"type":"character","attributes":{},"value":["tutorial-format.css","rstudio-theme.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9006"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["navigation"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/navigation-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tabsets.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["default.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["anchor-sections"]},{"type":"character","attributes":{},"value":["1.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/anchor-sections"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["anchor-sections.js"]},{"type":"character","attributes":{},"value":["anchor-sections.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.5"]}]}]}
</script>
<!--/html_preserve-->
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="execution_dependencies">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages","version"]},"class":{"type":"character","attributes":{},"value":["data.frame"]},"row.names":{"type":"integer","attributes":{},"value":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133]}},"value":[{"type":"character","attributes":{},"value":["abind","assertthat","backports","base","blob","broom","caret","caretEnsemble","cellranger","class","cli","codetools","coin","colorspace","compiler","crayon","curl","data.table","datasets","DBI","dbplyr","digest","DMwR","dplyr","e1071","ellipsis","evaluate","fansi","farver","fastmap","forcats","foreach","fs","generics","ggplot2","glmnet","glue","gower","graphics","grDevices","grid","gridExtra","gtable","haven","hms","htmltools","htmlwidgets","httpuv","httr","ipred","iterators","jsonlite","knitr","labeling","later","lattice","lava","learnr","libcoin","lifecycle","lubridate","magrittr","markdown","MASS","Matrix","matrixStats","methods","mime","ModelMetrics","modelr","modeltools","multcomp","munsell","mvtnorm","nlme","nnet","nnls","parallel","party","pbapply","pillar","pkgconfig","plyr","pROC","prodlim","promises","purrr","quantmod","R6","ranger","Rcpp","readr","readxl","recipes","reprex","reshape2","rlang","rmarkdown","ROCR","rpart","rprojroot","rstudioapi","rvest","sandwich","scales","shape","shiny","splines","stats","stats4","stringi","stringr","strucchange","SuperLearner","survival","TH.data","tibble","tidyr","tidyselect","tidyverse","timeDate","titanic","tools","TTR","utils","vctrs","withr","xfun","xml2","xtable","xts","yaml","zoo"]},{"type":"character","attributes":{},"value":["1.4-5","0.2.1","1.2.0","4.0.3","1.2.1","0.7.2","6.0-86","2.0.1","1.1.0","7.3-17","2.1.0","0.2-16","1.3-1","2.0-0","4.0.3","1.3.4","4.3","1.13.2","4.0.3","1.1.0","1.4.4","0.6.27","0.4.1","1.0.2","1.7-4","0.3.1","0.14","0.4.1","2.0.3","1.0.1","0.5.0","1.5.1","1.5.0","0.0.2","3.3.2","4.0-2","1.4.2","0.2.2","4.0.3","4.0.3","4.0.3","2.3","0.3.0","2.3.1","0.5.3","0.5.0.9002","1.5.2","1.5.4","1.4.2","0.9-9","1.0.13","1.7.1","1.30","0.4.2","1.1.0.1","0.20-41","1.6.8","0.10.1.9006","1.0-6","0.2.0","1.7.9","2.0.1","1.1","7.3-53","1.2-18","0.57.0","4.0.3","0.9","1.2.2.2","0.1.8","0.2-23","1.4-15","0.5.0","1.1-1","3.1-150","7.3-14","1.4","4.0.3","1.3-5","1.4-3","1.4.6","2.0.3","1.8.6","1.16.2","2019.11.13","1.1.1","0.3.4","0.4.17","2.5.0","0.12.1","1.0.5","1.4.0","1.3.1","0.1.14","0.3.0","1.4.4","0.4.8","2.5","1.0-11","4.1-15","2.0.2","0.13","0.3.6","3.0-0","1.1.1","1.4.5","1.5.0","4.0.3","4.0.3","4.0.3","1.5.3","1.4.0","1.5-2","2.0-26","3.2-7","1.0-10","3.0.4","1.1.2","1.1.0","1.3.0","3043.102","0.1.0","4.0.3","0.24.2","4.0.3","0.3.5","2.3.0","0.19","1.3.2","1.8-4","0.12.1","2.2.1","1.8-8"]}]}]}
</script>
<!--/html_preserve--></li>
</ul>
</div>

</div> <!-- topics -->

<div class="topicsContainer">
<div class="topicsPositioner">
<div class="band">
<div class="bandContent topicsListContainer">

<!-- begin doc-metadata -->
<div id="doc-metadata">
<h2 class="title toc-ignore" style="display:none;">ML Toolbox</h2>
</div>
<!-- end doc-metadata -->

</div> <!-- bandContent.topicsListContainer -->
</div> <!-- band -->
</div> <!-- topicsPositioner -->
</div> <!-- topicsContainer -->


</div> <!-- bandContent page -->
</div> <!-- pageContent band -->




<script>
// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>


</body>

</html>
